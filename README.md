This is my final project for Introduction to Deep Learning as part of academic credit. Given a series of MRI scans, identify and classify any brain tumors Gliomas, a type of brain tumor, are the most common primary brain tumors in adults. Our task is to take a series of magnetic resonant images or MRIs and identify and  classify any brain tumors. For this, we developed attention-swin-UNETR. The Swin U-Net architecture, also known as Swin-Transformer U-Net, is a variant of the U-Net architecture that incorporates the Swin Transformer into the traditional U-Net architecture and CNN as decoder. It has shown promising results in various medical image analysis tasks, including segmentation, due to its ability to capture long-range dependencies and spatial relationships in images. The Swin Transformer is organized into multiple stages, with each stage processing the input data at a different spatial resolution. It starts by partitioniong the input into non-overlapping patches. These patches are processed hierarchically through a series of stages, each consisting of transformer layers. It uses cross-window and shifted attention mechanisms to enable effective information exchange between neighboring patches. This helps improve feature representation and facilitates long-range dependencies. The decoder consists of residual block with 2 convolution layers. But this takes a lot of time and computation power, to improve the efficiency, we include the following modules
Attention- redundancy in features from skip connections, to better fuse the features together.
Spatial attention- Focuses on local features given a feature map. It conveys what within the feature map is essential to learn. For example, when driving a car, reading the speedometer requires a narrow focus of spatial attention.
Channel attention- Focuses on global features given some feature maps. It produces one dimension (1D) tensor for given feature maps, which is activated by the sigmoid function. It says which feature map is important for learning and enhances it.
